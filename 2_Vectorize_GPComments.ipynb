{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from scipy.sparse import save_npz\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk import WordNetLemmatizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "PATH_DATA = './data/GPComments'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:01<00:00,  4.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "   title                          text  score\n0    NaN  Tik tok is the best app ever      5\n1    NaN                     I love it      5\n2    NaN                          Nice      5\n3    NaN                         GREAT      5\n4    NaN                          Good      3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>Tik tok is the best app ever</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>I love it</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>Nice</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>GREAT</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>Good</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_path = os.path.join(PATH_DATA, '*.json')\n",
    "data_files_list = glob.glob(search_path)\n",
    "data_frame_list = []\n",
    "for path in tqdm(data_files_list):\n",
    "    df = pd.read_json(path, orient='records')\n",
    "    data_frame_list.append(df['text', 'score'])\n",
    "\n",
    "df = pd.concat(data_frame_list, axis=0)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "24993888\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='all', subset='text', inplace=True)\n",
    "print(df['text'].isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                          text  score  labels\n99995     Does not load at all      1       0\n99996                  Its fun      5       1\n99997         I love I love it      5       1\n99998  It won't let me play it      1       0\n99999                 Its good      5       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>score</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99995</th>\n      <td>Does not load at all</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>Its fun</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>I love I love it</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>It won't let me play it</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>Its good</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'] = (df['score'] >= 3).astype(np.int32).values\n",
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "data_version = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        pattern_token = r'(?u)(\\b[a-z]{2,}\\b|[\\u263a-\\U0001f645]|!|\\?)'\n",
    "        self.__regex_token = re.compile(pattern_token)\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        tokens = []\n",
    "        for match in self.__regex_token.finditer(sentence):\n",
    "            start, end = match.start(), match.end()\n",
    "            token_text = sentence[start: end]\n",
    "            token_text_lemmatized = self.lemmatizer.lemmatize(token_text)\n",
    "            tokens.append(token_text_lemmatized)\n",
    "\n",
    "        return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "tokenizer = LemmaTokenizer()\n",
    "stop_words_lematized = [tokenizer.lemmatizer.lemmatize(word) for word in ENGLISH_STOP_WORDS]\n",
    "stop_words_lematized.append('shall')\n",
    "vectorizer = CountVectorizer(\n",
    "                            tokenizer=tokenizer,\n",
    "                            strip_accents='unicode',\n",
    "                            lowercase=True,\n",
    "                            stop_words=stop_words_lematized,\n",
    "                            ngram_range=(1, 2),\n",
    "                            min_df=1000,\n",
    "                            binary=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "text_vectorized = vectorizer.fit_transform(df['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(24993888, 19961)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorized.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "scipy.sparse.csr.csr_matrix"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_vectorized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "['./data/gp_vectorized/data_headers_0.sav']"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_params = {\n",
    "    'vocabulary_': vectorizer.vocabulary_,\n",
    "}\n",
    "dump(vectorizer_params, f'./data/gp_vectorized/data_headers_{data_version}.sav')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "save_npz(f'./data/gp_vectorized/data_vectorized_{data_version}.npz', text_vectorized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "df.to_csv('./data/gp_vectorized/labels.csv', columns=['labels'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "Python (review_classifier)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}