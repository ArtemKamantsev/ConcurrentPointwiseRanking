{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from scipy.sparse import vstack\n",
    "from scipy.stats import sem\n",
    "from sklearn.model_selection import cross_validate, RepeatedKFold\n",
    "from sklearn.metrics import precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                          labels\n0                                [0, 0, 0, 1, 0]\n1                                   [0, 0, 1, 0]\n2                                      [0, 0, 1]\n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n4                                   [1, 0, 0, 0]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[1, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load('./data/glaw/data_vectorized_0.sav')\n",
    "df_labels = pd.read_csv('./data/glaw/labels.csv', index_col=0)\n",
    "print(len(data))\n",
    "df_labels.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "(419, 419)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels['labels'] = df_labels['labels'].apply(eval)\n",
    "multi_candidate_mask = df_labels['labels'].apply(lambda l: len(l) > 1).to_numpy()\n",
    "df_labels = df_labels[multi_candidate_mask]\n",
    "labels = df_labels['labels'].to_numpy()\n",
    "\n",
    "data = np.array(data)\n",
    "data = data[multi_candidate_mask]\n",
    "len(data), len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def reveal_spase(sparse_list):\n",
    "    return vstack(sparse_list, format='csr')\n",
    "\n",
    "def reveal_np(np_list):\n",
    "    return np.concatenate(np_list, axis=0)\n",
    "\n",
    "def reveal_set(data_, labels_):\n",
    "    return reveal_spase(data_), reveal_np(labels_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "class CustomEstimator:\n",
    "    def __init__(self, model=None):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        train_data_revealed, train_labels_revealed = reveal_set(X, Y)\n",
    "        self.model.fit(train_data_revealed, train_labels_revealed)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        return {'model': self.model}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def evaluate(estimator, test_data_list, test_labels_list):\n",
    "    \"\"\"Evaluate estimator on each document from `test_data_list`\n",
    "\n",
    "    :param estimator: sklearn estimator\n",
    "    :param test_data_list: list of sparce matrices\n",
    "    :param test_labels_list: 2d list of labels\n",
    "    :return: precision and roc-auc scores (calculates by macro-averaging corresponding scores of each document)\n",
    "    \"\"\"\n",
    "    precision_batch = []\n",
    "    roc_auc_batch = []\n",
    "    for test_data_batch, test_labels_batch in zip(test_data_list, test_labels_list):\n",
    "        positive_class_proba = estimator.model.predict_proba(test_data_batch)[:, 1]\n",
    "\n",
    "        max_p_idx = np.argmax(positive_class_proba)\n",
    "        predicted_labels_batch = [0] * len(positive_class_proba)\n",
    "        predicted_labels_batch[max_p_idx] = 1\n",
    "        if len(test_labels_batch) == 1:\n",
    "            print(test_labels_batch)\n",
    "        precision_batch.append(precision_score(test_labels_batch, predicted_labels_batch))\n",
    "        roc_auc_batch.append(roc_auc_score(test_labels_batch, positive_class_proba))\n",
    "\n",
    "    return {\n",
    "        'precision': np.average(precision_batch),\n",
    "        'roc-auc': np.average(roc_auc_batch)\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "def repeated_cross_validation(estimator, X, y, k=10, r=7, random_state=42, verbose=1):\n",
    "    cv = RepeatedKFold(n_splits=k, n_repeats=r, random_state=random_state)\n",
    "    result = cross_validate(\n",
    "        estimator=estimator,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        scoring=evaluate,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=verbose,\n",
    "        return_train_score=True,\n",
    "        error_score='raise',\n",
    "    )\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def statistics_from_cv(cv_result):\n",
    "    scores_precision = cv_result['test_precision']\n",
    "    scores_roc_auc = cv_result['test_roc-auc']\n",
    "\n",
    "    return {\n",
    "        'precision mean': np.mean(scores_precision),\n",
    "        'precision sem': sem(scores_precision),\n",
    "        'roc-auc mean': np.mean(scores_roc_auc),\n",
    "        'roc-auc sem': sem(scores_roc_auc),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "def enumerate_repeats(estimator, X, y, from_=1, to=11, k=10, random_state=42):\n",
    "    print(\"%3s %15s %15s %15s %15s\" % ('r', 'roc-auc mean', 'roc-auc sem', 'precision mean', 'precision sem'))\n",
    "    for r in range(from_, to):\n",
    "        cv_results = repeated_cross_validation(estimator, X, y, random_state=random_state, r=r, k=k, verbose=0)\n",
    "        stats = statistics_from_cv(cv_results)\n",
    "\n",
    "        print(\"%3d %15.10f %15.10f %15.10f %15.10f\" % (\n",
    "            r, stats['roc-auc mean'], stats['roc-auc sem'], stats['precision mean'], stats['precision sem']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "estimator_mnb = CustomEstimator(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  r    roc-auc mean     roc-auc sem  precision mean   precision sem\n",
      "  1    0.9659664152    0.0022094528    0.9235772358    0.0093113416\n",
      "  2    0.9660046844    0.0018321349    0.9235191638    0.0081205899\n",
      "  3    0.9659507979    0.0015389978    0.9235965931    0.0063405159\n",
      "  4    0.9665331883    0.0013284168    0.9236062718    0.0052300760\n",
      "  5    0.9661960984    0.0013316978    0.9236469222    0.0048312151\n",
      "  6    0.9662468052    0.0013263490    0.9240224545    0.0044977337\n",
      "  7    0.9662695981    0.0012379529    0.9246557159    0.0041470142\n",
      "  8    0.9664114042    0.0012118391    0.9251306620    0.0039806504\n",
      "  9    0.9663713052    0.0011858848    0.9252419667    0.0037947436\n",
      " 10    0.9664186934    0.0011844335    0.9257955865    0.0037138816\n"
     ]
    }
   ],
   "source": [
    "enumerate_repeats(estimator_mnb, data, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision mean': 0.9246557159449146,\n 'precision sem': 0.004147014163838121,\n 'roc-auc mean': 0.9662695980812572,\n 'roc-auc sem': 0.0012379528829737313}"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = repeated_cross_validation(estimator_mnb, data, labels, verbose=2)\n",
    "stats = statistics_from_cv(cv_results)\n",
    "stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "concurent_classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}